{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Copy of Device placement.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8EuPVDK0oXX"
      },
      "source": [
        "# Device placement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMepbBP-0oXb"
      },
      "source": [
        "In this reading, we are going to be looking at device placement. We will see how to access the device associated to a given tensor, and compare the use of GPUs and CPUs.\n",
        "\n",
        "When running this notebook, ensure that the GPU runtime type is selected (Runtime -> Change runtime type)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGJhiWHQ0oXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bada167-f0bf-4aa8-f70b-b3471b9aa789"
      },
      "source": [
        "! pip install tensorflow==2.1.0\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.1.0\n",
            "  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8 MB 27 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.37.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.47.0)\n",
            "Collecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.2.0,>=2.1.0\n",
            "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.14.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.17.3)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 68.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.1.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=4ff25491e633fbaa82c5861cd737d9cde7772203d52c0ad1fa87629a00d39293\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, scipy, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.4.1 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.14 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 scipy-1.4.1 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n",
            "2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKcwCg6Ns_kt",
        "outputId": "19c9e366-f690-4362-e459-5acf07c4c9e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o07Lk8BE27-6"
      },
      "source": [
        "## Get the physical devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw5wPXyy2Zwp"
      },
      "source": [
        "First, we can list the physical devices available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB-00SsB2Z8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243bbb31-a69b-42f3-8e23-ab639406abd4"
      },
      "source": [
        "# List all physical devices\n",
        "\n",
        "tf.config.list_physical_devices()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
              " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBfa_PEw0oXk"
      },
      "source": [
        "If you have enabled the GPU runtime, then you should see the GPU device in the above list.\n",
        "\n",
        "We can also check specifically for the GPU or CPU devices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FgViTqb0oXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bafdc0c9-0836-4b13-ade9-a75d77e29670"
      },
      "source": [
        "# Check for GPU devices\n",
        "\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N857-C_B2yMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086ff3ef-3a0d-4388-911d-da40e6ee4723"
      },
      "source": [
        "# Check for CPU devices\n",
        "\n",
        "tf.config.list_physical_devices('CPU')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GStCHnkx0oXs"
      },
      "source": [
        "We can get the GPU device name as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlT6kf810oXu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "67e6ae3d-7d4f-419c-fd69-cdb0377c5a4c"
      },
      "source": [
        "# Get the GPU device name\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FNvARDH3KlC"
      },
      "source": [
        "## Placement of Tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB7qxgNL0oYA"
      },
      "source": [
        "TensorFlow will automatically allocate Tensor operations to a physical device, and will handle the copying between CPU and GPU memory if necessary. \n",
        "\n",
        "Let's define a random Tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQrsztEl0oYB"
      },
      "source": [
        "# Define a Tensor\n",
        "\n",
        "x = tf.random.uniform([3, 3])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTni7OPe0oYF"
      },
      "source": [
        "We can see which device this Tensor is placed on using its `device` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLSbukXa0oYH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19a254ac-f597-4b58-9d11-7ff6161bba86"
      },
      "source": [
        "# Get the Tensor device\n",
        "\n",
        "x.device"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/job:localhost/replica:0/task:0/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uVDrVK60oYM"
      },
      "source": [
        "The above string will end with `'GPU:K'` if the Tensor is placed on the `K`-th GPU device. We can also check if a tensor is placed on a specific device by using `device_endswith`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0ceL5Qy0oYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "014a97f7-0076-4b2d-967f-b664a3b74ff1"
      },
      "source": [
        "# Test for device allocation\n",
        "\n",
        "print(\"Is the Tensor on CPU #0:  \"),\n",
        "print(x.device.endswith('CPU:0'))\n",
        "print('')\n",
        "print(\"Is the Tensor on GPU #0:  \"),\n",
        "print(x.device.endswith('GPU:0'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the Tensor on CPU #0:  \n",
            "False\n",
            "\n",
            "Is the Tensor on GPU #0:  \n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtEi2qnK4LyO"
      },
      "source": [
        "## Specifying device placement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33SlBwIA0oYQ"
      },
      "source": [
        "As mentioned previously, TensorFlow will automatically allocate Tensor operations to specific devices. However, it is possible to force placement on specific devices, if they are available. \n",
        "\n",
        "We can view the benefits of GPU acceleration by running some tests and placing the operations on the CPU or GPU respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEfz4RY90oYR"
      },
      "source": [
        "# Define simple tests to time computation speed\n",
        "\n",
        "import time\n",
        "\n",
        "def time_matadd(x):\n",
        "    start = time.time()\n",
        "    for loop in range(10):\n",
        "        tf.add(x, x)\n",
        "    result = time.time()-start\n",
        "    print(\"Matrix addition (10 loops): {:0.2f}ms\".format(1000*result))\n",
        "\n",
        "\n",
        "def time_matmul(x):\n",
        "    start = time.time()\n",
        "    for loop in range(10):\n",
        "        tf.matmul(x, x)\n",
        "    result = time.time()-start\n",
        "    print(\"Matrix multiplication (10 loops): {:0.2f}ms\".format(1000*result))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEd85pdw5N6c"
      },
      "source": [
        "In the following cell, we run the above tests inside the context `with tf.device(\"CPU:0\")`, which forces the operations to be run on the CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB5Z1iUT0oYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f92300b-0960-4846-f271-30f95bb3bc29"
      },
      "source": [
        "# Force execution on CPU\n",
        "\n",
        "print(\"On CPU:\")\n",
        "with tf.device(\"CPU:0\"):\n",
        "    x = tf.random.uniform([1000, 1000])\n",
        "    assert x.device.endswith(\"CPU:0\")\n",
        "    time_matadd(x)\n",
        "    time_matmul(x)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On CPU:\n",
            "Matrix addition (10 loops): 9.51ms\n",
            "Matrix multiplication (10 loops): 242.25ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN3ZHIMD50kB"
      },
      "source": [
        "And now run the same operations on the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7AryQq60oYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66924fcd-e546-4a75-f01d-06eda8ec11c9"
      },
      "source": [
        "# Force execution on GPU #0 if available\n",
        "\n",
        "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
        "    print(\"On GPU:\")\n",
        "    with tf.device(\"GPU:0\"): \n",
        "        x = tf.random.uniform([1000, 1000])\n",
        "        assert x.device.endswith(\"GPU:0\")\n",
        "        time_matadd(x)\n",
        "        time_matmul(x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On GPU:\n",
            "Matrix addition (10 loops): 0.12ms\n",
            "Matrix multiplication (10 loops): 1.11ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqJR83G354Zh"
      },
      "source": [
        "Note the significant time difference between running these operations on different devices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFOJkxMk-HL_"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gBgorhv-HWE"
      },
      "source": [
        "Finally, we will demonstrate that GPU device placement offers speedup benefits for model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa7Vvbne6QS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad11a19-4c58-4fef-c645-5cbcae544575"
      },
      "source": [
        "# Load the MNIST dataset\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train/255., x_test/255."
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJgFyw0567Dn"
      },
      "source": [
        "# Reduce the dataset size to speed up the test\n",
        "\n",
        "x_train, y_train = x_train[:1000], y_train[:1000]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vD2d7al4_VZ"
      },
      "source": [
        "# Define a function to build the model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import  Sequential\n",
        "\n",
        "def get_model():\n",
        "  model = Sequential([\n",
        "      layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
        "      layers.MaxPooling2D((2, 2)),\n",
        "      layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "      layers.MaxPooling2D((2, 2)),\n",
        "      layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "      layers.MaxPooling2D((2, 2)),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(10, activation='softmax'),\n",
        "      ])\n",
        "  return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxEcTFQb7hRt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80042089-b794-4a5d-f24a-b9f594e28b3a"
      },
      "source": [
        "# Time a training run on the CPU\n",
        "\n",
        "with tf.device(\"CPU:0\"):\n",
        "  model = get_model()\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  start = time.time()\n",
        "  model.fit(x_train[..., np.newaxis], y_train, epochs=5, verbose=0)\n",
        "  result = time.time() - start\n",
        "\n",
        "print(\"CPU training time: {:0.2f}ms\".format(1000 * result))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU training time: 6819.12ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9_G4sak5dHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb81f173-c1fc-41d7-cf65-9e15a0540497"
      },
      "source": [
        "# Time a training run on the GPU\n",
        "\n",
        "with tf.device(\"GPU:0\"):\n",
        "  model = get_model()\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  start = time.time()\n",
        "  model.fit(x_train[..., np.newaxis], y_train, epochs=5, verbose=0)\n",
        "  result = time.time() - start\n",
        "\n",
        "print(\"GPU training time: {:0.2f}ms\".format(1000 * result))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU training time: 1073.55ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_O9D-XI0oYa"
      },
      "source": [
        "## Further reading and resources \n",
        "* https://www.tensorflow.org/tutorials/customization/basics#gpu_acceleration"
      ]
    }
  ]
}