{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lMCKMj4PN1kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45961d66-4629-47df-e1c6-20f7cc802198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_giJYKbvN1kG"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTmw8odDN1kI"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zudr-QVVN1kJ"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m-kxxODpN1kK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_AdscjBN1kK"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zqgWAtDoN1kL"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "\n",
        "class MyModel(Model):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense_1 = Dense(64, activation='relu')\n",
        "        self.dense_2 = Dense(10)\n",
        "        self.dropout = Dropout(0.4)\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        x = self.dense_1(inputs)\n",
        "\n",
        "        if training:\n",
        "            x = self.dropout(x)\n",
        "            \n",
        "        return self.dense_2(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vFicLxBON1kM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6ca8c1-7d38-42d5-a42b-47afb7d2f621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               multiple                  704       \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  650       \n",
            "                                                                 \n",
            " dropout (Dropout)           multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,354\n",
            "Trainable params: 1,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1, 10]))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense_1 = Dense(64)\n",
        "        self.dense_2 = Dense(10)\n",
        "        self.dense_3 = Dense(5)\n",
        "        self.softmax = Softmax()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense_1(inputs)\n",
        "        y1 = self.dense_2(inputs)\n",
        "        y2 = self.dense_3(y1)\n",
        "        concat = concatenate([x, y2])\n",
        "\n",
        "        return self.softmax(concat)\n"
      ],
      "metadata": {
        "id": "AVZ0ScnCRGqZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel()\n",
        "model(tf.random.uniform([1,10]))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUchADohR7dZ",
        "outputId": "3c0ecff9-e3dd-442b-f283-18c0076d187b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             multiple                  704       \n",
            "                                                                 \n",
            " dense_3 (Dense)             multiple                  110       \n",
            "                                                                 \n",
            " dense_4 (Dense)             multiple                  55        \n",
            "                                                                 \n",
            " softmax (Softmax)           multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 869\n",
            "Trainable params: 869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpB2ulpzN1kN"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LP6LcZ0lN1kO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmALFceZN1kO"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9Wf3qJBvN1kP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd125d92-d07d-4392-fc6a-02ce259fb445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[ 0.17023557 -0.06952328  0.21984395]], shape=(1, 3), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[ 0.13540995, -0.01776023,  0.04418695],\n",
            "       [ 0.01764113,  0.11468474, -0.0441861 ],\n",
            "       [ 0.04134449, -0.08330353,  0.09496459],\n",
            "       [-0.05472815, -0.08774783,  0.05439732],\n",
            "       [ 0.03056816,  0.00460357,  0.07048119]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ]
        }
      ],
      "source": [
        "# Create a custom layer\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(units,), initializer='zeros')\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "\n",
        "dense_layer = MyLayer(3, 5)\n",
        "x = tf.ones((1, 5))\n",
        "\n",
        "print(dense_layer(x))\n",
        "print(dense_layer.weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5auMmnRSN1kQ"
      },
      "outputs": [],
      "source": [
        "# Specify trainable weights\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal', trainable=False)\n",
        "        self.b = self.add_weight(shape=(units,), initializer='zeros', trainable=False)\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "\n",
        "dense_layer = MyLayer(3, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q8jA8MgqN1kQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81421996-a679-42cd-fb36-281cceb8508c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable weights: 0\n",
            "non-trainable weights: 2\n"
          ]
        }
      ],
      "source": [
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VQ7zWvxnN1kR"
      },
      "outputs": [],
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "\n",
        "class MyLayerMean(Layer):\n",
        "\n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayerMean, self).__init__()\n",
        "        self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal', trainable=False)\n",
        "        self.b = self.add_weight(shape=(units,), initializer='zeros', trainable=False)\n",
        "        self.sum_activation = tf.Variable(initial_value=tf.zeros((units,)), trainable=False)\n",
        "        self.number_call = tf.Variable(initial_value=0, trainable=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        activations = tf.matmul(inputs, self.w) + self.b\n",
        "        self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
        "        self.number_call.assign_add(inputs.shape[0])\n",
        "        return activations, self.sum_activation / tf.cast(self.number_call, tf.float32)\n",
        "\n",
        "\n",
        "dense_layer = MyLayerMean(3, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xreyDglqN1kS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9bc6b9-4abe-405e-c8a1-9a07bb8d58e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.13416645  0.21673462 -0.02175037]\n",
            "[-0.13416645  0.21673462 -0.02175037]\n"
          ]
        }
      ],
      "source": [
        "# Test the layer\n",
        "# the weights do not change because we are not changing the weights and biases\n",
        "# this can be useful if we want to analyze the propagation\n",
        "# of signals in a network\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-MAK7EfWN1kS"
      },
      "outputs": [],
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7GPIuYaN1kT"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zOT1MK8dN1kT"
      },
      "outputs": [],
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Softmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return self.softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hN4QHmjVN1kT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09035bc-bffa-4576-a406-7511089235dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.03249924 0.01518492 0.03520592 0.02216888 0.02571679 0.01440755\n",
            "  0.01969794 0.01210358 0.02236021 0.01625276 0.01886163 0.02548575\n",
            "  0.02238332 0.01406043 0.01395061 0.02218554 0.01719143 0.02481675\n",
            "  0.0311988  0.02192876 0.04051666 0.02415468 0.01641873 0.0074969\n",
            "  0.02222106 0.01114113 0.02923696 0.0318312  0.00748392 0.02235615\n",
            "  0.08034562 0.01477216 0.03455975 0.01846828 0.01849226 0.02586483\n",
            "  0.01069667 0.0069191  0.01774755 0.01519515 0.02114782 0.01858312\n",
            "  0.02923378 0.01488368 0.01054317 0.02202893]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " my_layer_2 (MyLayer)        multiple                  640064    \n",
            "                                                                 \n",
            " my_dropout (MyDropout)      multiple                  0         \n",
            "                                                                 \n",
            " my_layer_3 (MyLayer)        multiple                  4160      \n",
            "                                                                 \n",
            " my_dropout_1 (MyDropout)    multiple                  0         \n",
            "                                                                 \n",
            " my_layer_4 (MyLayer)        multiple                  2990      \n",
            "                                                                 \n",
            " softmax_1 (Softmax)         multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 0\n",
            "Non-trainable params: 647,214\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpTXIGm4N1kU"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0lTFrE9dN1kU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5aPu0d9N1kV"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "K9uFlAxGN1kW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a452c9a0-9a09-49bb-9947-7935fe86080d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f89f2391d10>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "m=1\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33XMa-p1N1kW"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lQEb_jiPN1kW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ALUraTavN1kX"
      },
      "outputs": [],
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n",
        "class LinearRegressionLayer(Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LinearRegressionLayer, self).__init__()\n",
        "        self.m = self.add_weight(shape=(1,), initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(1,), initializer='zeros')\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.m * inputs + self.b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regression_layer = LinearRegressionLayer()"
      ],
      "metadata": {
        "id": "m2-DZt6ySc_n"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for attr in dir(linear_regression_layer):\n",
        "#     print(\"obj.%s = %r\" % (attr, getattr(linear_regression_layer, attr)))"
      ],
      "metadata": {
        "id": "QoDMGgu4Shyn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(linear_regression_layer(x_train))\n",
        "print(linear_regression_layer.weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EoonYAVTlvx",
        "outputId": "a3ab6e6f-545a-4678-f5f8-917fbe6e3ce2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.02519771 -0.02198721 -0.02449995 -0.03610049 -0.00622328 -0.05700725\n",
            " -0.0015776  -0.01899617 -0.01979944 -0.02670473 -0.01637697 -0.00735377\n",
            " -0.06171056 -0.04061648 -0.01888262 -0.02573195 -0.04984999 -0.02377238\n",
            " -0.00778639 -0.04284893], shape=(20,), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-0.06491695], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_LN_fjhN1kX"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mSpkFfYrN1kY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16612fd0-6044-415c-a54b-0b510c94f240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting loss 6.030117\n"
          ]
        }
      ],
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
        "\n",
        "starting_loss = SquaredError(linear_regression_layer(x_train), y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSntRVY1N1kY"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the trainable variables used in the calculation of the gradient\n",
        "print(linear_regression_layer.trainable_variables)\n",
        "\n",
        "print(linear_regression_layer.m)\n",
        "print(linear_regression_layer.b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCXG3_1ccFzV",
        "outputId": "2c2b99a6-e1c1-4bf0-d3db-0c84c2313de3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-0.06491695], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n",
            "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-0.06491695], dtype=float32)>\n",
            "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AbC-hVPvN1kY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75473f41-d4e7-41bd-c1d5-a9e861ae2b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0, Loss: 6.030117\n",
            "Step: 1, Loss: 4.696500\n",
            "Step: 2, Loss: 3.658597\n",
            "Step: 3, Loss: 2.850836\n",
            "Step: 4, Loss: 2.222185\n",
            "Step: 5, Loss: 1.732930\n",
            "Step: 6, Loss: 1.352161\n",
            "Step: 7, Loss: 1.055822\n",
            "Step: 8, Loss: 0.825193\n",
            "Step: 9, Loss: 0.645702\n",
            "Step: 10, Loss: 0.506010\n",
            "Step: 11, Loss: 0.397293\n",
            "Step: 12, Loss: 0.312682\n",
            "Step: 13, Loss: 0.246833\n",
            "Step: 14, Loss: 0.195584\n",
            "Step: 15, Loss: 0.155698\n",
            "Step: 16, Loss: 0.124656\n",
            "Step: 17, Loss: 0.100497\n",
            "Step: 18, Loss: 0.081694\n",
            "Step: 19, Loss: 0.067060\n",
            "Step: 20, Loss: 0.055670\n",
            "Step: 21, Loss: 0.046806\n",
            "Step: 22, Loss: 0.039906\n",
            "Step: 23, Loss: 0.034536\n",
            "Step: 24, Loss: 0.030357\n"
          ]
        }
      ],
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n",
        "learning_rate = 0.05\n",
        "steps = 25\n",
        "\n",
        "for i in range(steps):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = linear_regression_layer(x_train)\n",
        "        loss = SquaredError(predictions, y_train)\n",
        "\n",
        "    gradients = tape.gradient(loss, linear_regression_layer.trainable_variables)\n",
        "\n",
        "    linear_regression_layer.m.assign_sub(learning_rate * gradients[0])\n",
        "    linear_regression_layer.b.assign_sub(learning_rate * gradients[1])\n",
        "\n",
        "    print('Step: %d, Loss: %f' % (i, loss))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rrQeXIwpN1kY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "81ef347e-b4a1-46b0-cb7f-230269be2088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m:1,  trained m:[0.80312365]\n",
            "b:2,  trained b:[1.9790715]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f89f22b8b90>]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"m:{},  trained m:{}\".format(m,linear_regression_layer.m.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression_layer.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
        "plt.plot(x_linear_regression, linear_regression_layer.m*x_linear_regression+linear_regression_layer.b, 'r.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwbub9saN1kZ"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nSadhK6bN1kZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1zSy0NeN1kZ"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qzhpMEMbN1kZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "evM-K4jxN1ka"
      },
      "outputs": [],
      "source": [
        "# Define the custom layers and model\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "    def __init__(self, units):\n",
        "        super(MyLayer, self).__init__()\n",
        "\n",
        "        self.units = units\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units), \n",
        "                                 initializer='random_normal',\n",
        "                                 name='kernel')\n",
        "        self.b = self.add_weight(shape=(self.units,), \n",
        "                                 initializer='zeros',\n",
        "                                 name='bias')\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)\n",
        "\n",
        "\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3)\n",
        "        self.softmax = Softmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        return self.softmax(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(64, 64, 46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1LSkA3es6JH",
        "outputId": "10587035-14b0-4402-9ad5-510cea51fb7b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.00568503 0.01397724 0.0403087  0.02013211 0.04196637 0.01424354\n",
            "  0.01819351 0.0164536  0.00842858 0.0136298  0.00683523 0.03333626\n",
            "  0.03879611 0.00114234 0.00796559 0.07881483 0.00535741 0.0161962\n",
            "  0.02258131 0.01190623 0.06885441 0.01708183 0.04503251 0.03423188\n",
            "  0.02035045 0.00076327 0.02712091 0.00781009 0.02693769 0.02007902\n",
            "  0.01524629 0.0183035  0.01323194 0.0053593  0.01178917 0.03646528\n",
            "  0.0327453  0.05121071 0.01476681 0.01424032 0.03572819 0.00991455\n",
            "  0.01121988 0.01289005 0.01712087 0.01555579]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " my_layer_5 (MyLayer)        multiple                  640064    \n",
            "                                                                 \n",
            " my_dropout_2 (MyDropout)    multiple                  0         \n",
            "                                                                 \n",
            " my_layer_6 (MyLayer)        multiple                  4160      \n",
            "                                                                 \n",
            " my_dropout_3 (MyDropout)    multiple                  0         \n",
            "                                                                 \n",
            " my_layer_7 (MyLayer)        multiple                  2990      \n",
            "                                                                 \n",
            " softmax_2 (Softmax)         multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7c93lPrN1ka"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ANMhC4BGN1ka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fbb6afe-a380-41d3-e279-e21fe3bcb85a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2110848/2110848 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "kAZEY68nN1kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af657ce6-9352-4f92-e5be-551c79f6e7ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: earn\n"
          ]
        }
      ],
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RovVNBh2N1kd"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = reuters.get_word_index()\n",
        "print(list(word_to_index.items())[:5]) # print first 5 items\n",
        "inverted_word_index = dict([(value, key) for key, value in word_to_index.items()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kXpDyw3wOEo",
        "outputId": "dbfbe5d8-99b9-4fbc-be2b-25f9b32bafbe"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "550378/550378 [==============================] - 0s 0us/step\n",
            "[('mdbl', 10996), ('fawc', 16260), ('degussa', 12089), ('woods', 8803), ('hanging', 13796)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first 5 items\n",
        "print(list(inverted_word_index.items())[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StSC8pk3wxfv",
        "outputId": "3e84fc8e-21c9-41cb-e615-fc30483e5845"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(10996, 'mdbl'), (16260, 'fawc'), (12089, 'degussa'), (8803, 'woods'), (13796, 'hanging')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DexW14I-N1ke"
      },
      "outputs": [],
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "text_news = ' '.join([inverted_word_index.get(i - 3, '?') for i in train_data[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "AuIOSMg3N1ke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d8450231-14d4-4f63-9789-eb5ce874da2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Print the first data example sentence\n",
        "\n",
        "text_news"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OKWpvUqN1ke"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "HnbjXWkZN1ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f81d779-db60-443b-b638-b0fa900d1128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train: (8982, 10000)\n",
            "Shape of x_test: (2246, 10000)\n"
          ]
        }
      ],
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5e2Xk0xN1ke"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "DBoR9_i7N1kf"
      },
      "outputs": [],
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    \n",
        "    # we are adding a weight decay penalty for regularization purposes\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl9xgdNiN1kf"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PKAN9pTCN1kf"
      },
      "outputs": [],
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "iGm9UnuHN1kf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3721c85-fe8f-4eb4-9508-f7e651093f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 3.322, Accuracy: 0.476\n",
            "Epoch: 001, Loss: 1.919, Accuracy: 0.604\n",
            "Epoch: 002, Loss: 1.838, Accuracy: 0.652\n",
            "Epoch: 003, Loss: 1.779, Accuracy: 0.683\n",
            "Epoch: 004, Loss: 1.755, Accuracy: 0.688\n",
            "Epoch: 005, Loss: 1.739, Accuracy: 0.694\n",
            "Epoch: 006, Loss: 1.713, Accuracy: 0.700\n",
            "Epoch: 007, Loss: 1.705, Accuracy: 0.703\n",
            "Epoch: 008, Loss: 1.712, Accuracy: 0.708\n",
            "Epoch: 009, Loss: 1.694, Accuracy: 0.712\n",
            "Duration :171.379\n"
          ]
        }
      ],
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "\n",
        "# keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 10\n",
        "weight_decay = 0.005\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # define the metrics we are going to use\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "    for x, y in train_dataset:\n",
        "        # optimize the model\n",
        "        loss_value, grads = grad(model, x, y, weight_decay)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        # compute current loss\n",
        "        epoch_loss_avg(loss_value)\n",
        "\n",
        "        # compare predicted label to actual label\n",
        "        epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "    train_loss_results.append(epoch_loss_avg.result())\n",
        "    train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "    print('Epoch: {:03d}, Loss: {:.3f}, Accuracy: {:.3f}'.format(epoch, \n",
        "                                                                 epoch_loss_avg.result(), \n",
        "                                                                 epoch_accuracy.result()))\n",
        "\n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPAATjbtN1kf"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "kxNGN3rvN1kg"
      },
      "outputs": [],
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "bmptAPOQN1kg"
      },
      "outputs": [],
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WOfr85ReN1kg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962fbf36-b887-430f-f080-b59ad068f7a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.834\n",
            "Test accuracy: 67.275%\n"
          ]
        }
      ],
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value = loss(model, x, y, weight_decay)    \n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)  \n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU5mIItrN1kg"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "q_jZ7bbpN1kg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "ce23c3df-2be0-4415-f062-d5fd51df37cf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YJY5iAnN1kg"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "N6SWXRuGN1kh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288a5fd2-5b42-405d-f77d-4542d16ad275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: acq\n",
            "     Label: earn\n",
            "Other predictions: [0.28 0.14 0.14 0.04 0.03 0.03 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.   0.   0.   0.   0.   0.\n",
            " 0.   0.   0.   0.  ]\n"
          ]
        }
      ],
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "idx = np.random.randint(0, 5000)\n",
        "\n",
        "predictions = model(x_train[np.newaxis,idx])\n",
        "predicted_label = np.argmax(predictions,axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[idx]]))\n",
        "print(\"Other predictions: {}\".format(np.round(np.sort(predictions)[0][::-1], 2)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.round(np.array(predictions)[0], 2)\n",
        "indexes = list(np.argsort(np.array(predictions))[0][::-1])\n",
        "' '.join([f'{class_names[idx]} {preds[idx]}' for idx in indexes])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "ocXs3xhQGXhM",
        "outputId": "28cd7a0f-0b3f-48ac-9101-6bc4fdf4c494"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'acq 0.2800000011920929 grain 0.14000000059604645 earn 0.14000000059604645 trade 0.03999999910593033 sugar 0.029999999329447746 money-fx 0.029999999329447746 ship 0.019999999552965164 oilseed 0.019999999552965164 coffee 0.019999999552965164 veg-oil 0.019999999552965164 cocoa 0.009999999776482582 livestock 0.009999999776482582 gold 0.009999999776482582 crude 0.009999999776482582 interest 0.009999999776482582 wheat 0.009999999776482582 copper 0.009999999776482582 alum 0.009999999776482582 iron-steel 0.009999999776482582 bop 0.009999999776482582 cotton 0.009999999776482582 money-supply 0.009999999776482582 nat-gas 0.009999999776482582 reserves 0.009999999776482582 pet-chem 0.009999999776482582 carcass 0.009999999776482582 orange 0.009999999776482582 rubber 0.009999999776482582 dlr 0.009999999776482582 tin 0.009999999776482582 jobs 0.009999999776482582 meal-feed 0.009999999776482582 gas 0.009999999776482582 ipi 0.009999999776482582 zinc 0.009999999776482582 cpi 0.009999999776482582 strategic-metal 0.0 housing 0.0 lead 0.0 retail 0.0 gnp 0.0 wpi 0.0 silver 0.0 hog 0.0 heat 0.0 lei 0.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd7xiGXoN1kh"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "AC9X372UN1kh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfpRQpBFN1kh"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ZOuRvW_lN1kh"
      },
      "outputs": [],
      "source": [
        "# Initialize a new model\n",
        "\n",
        "model = MyModel(64, 64, 46)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjNNUOxNN1ki"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "XiXvsu31N1ki"
      },
      "outputs": [],
      "source": [
        "# Use the @tf.function decorator\n",
        "\n",
        "@tf.function\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4cnOe3bN1ki"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "6jHOA0iHN1ki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dbaf9ea-366b-4060-c0fd-730cab668e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 2.421, Accuracy: 0.563\n",
            "Epoch: 001, Loss: 1.924, Accuracy: 0.654\n",
            "Epoch: 002, Loss: 1.837, Accuracy: 0.677\n",
            "Epoch: 003, Loss: 1.780, Accuracy: 0.685\n",
            "Epoch: 004, Loss: 1.756, Accuracy: 0.688\n",
            "Epoch: 005, Loss: 1.734, Accuracy: 0.693\n",
            "Epoch: 006, Loss: 1.715, Accuracy: 0.697\n",
            "Epoch: 007, Loss: 1.708, Accuracy: 0.699\n",
            "Epoch: 008, Loss: 1.710, Accuracy: 0.706\n",
            "Epoch: 009, Loss: 1.685, Accuracy: 0.704\n",
            "Duration :118.736\n"
          ]
        }
      ],
      "source": [
        "# Re-run the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))\n",
        "train_dataset = train_dataset.batch(32)\n",
        "\n",
        "\n",
        "# keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 10\n",
        "weight_decay = 0.005\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # define the metrics we are going to use\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "    for x, y in train_dataset:\n",
        "        # optimize the model\n",
        "        loss_value, grads = grad(model, x, y, weight_decay)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        # compute current loss\n",
        "        epoch_loss_avg(loss_value)\n",
        "\n",
        "        # compare predicted label to actual label\n",
        "        epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "    train_loss_results.append(epoch_loss_avg.result())\n",
        "    train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "    print('Epoch: {:03d}, Loss: {:.3f}, Accuracy: {:.3f}'.format(epoch, \n",
        "                                                                 epoch_loss_avg.result(), \n",
        "                                                                 epoch_accuracy.result()))\n",
        "\n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_95hN_mJN1ki"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "eR5dV4lpN1ki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e56ffe0-2d85-4cac-9c92-f8e350b0c0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def tf__grad(model, inputs, targets, wd):\n",
            "    with ag__.FunctionScope('grad', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "        with ag__.ld(tf).GradientTape() as tape:\n",
            "            loss_value = ag__.converted_call(ag__.ld(loss), (ag__.ld(model), ag__.ld(inputs), ag__.ld(targets), ag__.ld(wd)), None, fscope)\n",
            "        try:\n",
            "            do_return = True\n",
            "            retval_ = (ag__.ld(loss_value), ag__.converted_call(ag__.ld(tape).gradient, (ag__.ld(loss_value), ag__.ld(model).trainable_variables), None, fscope))\n",
            "        except:\n",
            "            do_return = False\n",
            "            raise\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n",
        "print(tf.autograph.to_code(grad.python_function))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}